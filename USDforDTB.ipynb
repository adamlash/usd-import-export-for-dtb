{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99aca595-8b2c-4dd9-8809-7f4dc7403daf",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### üåê Step 0: Install required imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68796ffc-fa13-4948-849e-e95fec179e3f",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Pip installations\n",
    "%pip install usd-core --quiet\n",
    "%pip install spark --quiet\n",
    "%pip install thefuzz --quiet\n",
    "# Import Open USD MSFabric Package\n",
    "%pip install /lakehouse/default/Files/openusd_msfabric_toolkit-0.1.0-py3-none-any.whl --quiet\n",
    "# Imports\n",
    "from pxr import Usd, UsdGeom, Sdf\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from openusd_msfabric_toolkit import OpenUSDToolkit\n",
    "# Create Spark Session\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fdee4d-97ee-44c0-9c94-88c213b421e3",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### üìù Step 1: Provide name of USD file, Asset data table, and Lakehouse\n",
    "Please update the Python cell below.\n",
    "Please note that your files must be located in the `/lakehouse/default/Files/` directory.\n",
    "\n",
    "Note, please just supply the file name - not the file path. Example file name:\n",
    "```\n",
    "PCR_8FT2_ALL_Complete_wOneRobot.usd\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbc2a18-7dd1-4458-9b33-2efcae4c08c7",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# USD File Details\n",
    "usd_file_name = \"iss.usdc\"  # Name of the USD file you want to enrich\n",
    "usd_lakehouse_name = \"yourlakehouse\" # Name of the lakehouse in which your USD file is stored\n",
    "\n",
    "# Asset Data Details\n",
    "entity_name = \"Module\" # Name of the Entity Type you wish to match with the USD Metadata. This is case sensitive!\n",
    "dtb_item = \"yourdtb\" # Name of your DTB Instance. This is case sensitive!\n",
    "\n",
    "# Do not modify\n",
    "usd_file_path = f\"/lakehouse/default/Files/{usd_file_name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b8679b-6f94-460f-9283-2f0bf1c62dea",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### üìÇ Step 2: Extract metadata from your USD file\n",
    "This step extracts metadata from prims of type Xform. This data will be stored in a table titled **ExtractedUSDMetadata** in your **default** Lakehouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff8f312-0865-4d1f-8e97-10135c6bb572",
   "metadata": {
    "collapsed": false,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Do not modify\n",
    "df_metadata = OpenUSDToolkit.read_usd_metadata(usd_file_path, spark)\n",
    "sql_query = f\"SELECT * FROM {usd_lakehouse_name}.extractedusdmetadata\"\n",
    "df_usd_metadata = spark.sql(sql_query)\n",
    "display(df_usd_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36a11fb-fd5f-412e-8ba3-9f705cef7100",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### üß© Step 3: Relate Asset Data and extracted USD metadata\n",
    "This step fuzzy matches your asset data in your Lakehouse with the extracted USD metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf404013-fb9f-4e02-9eca-138fd2326d8e",
   "metadata": {
    "collapsed": false,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Do not modify\n",
    "df_entity_instances = OpenUSDToolkit.read_entity_instances(spark, dtb_item, entity_name)\n",
    "display(df_entity_instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dbc72f-baa4-44ed-9e44-f75e1e3fc616",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "The fuzzy matching threshold determines how closely the asset names must match the USD metadata in order to be considered a valid match. You may wish to set the thresholds of matching strength with the variable `fuzzy_threshold` . We are using the Fuzzy matching library called [TheFuzz](https://github.com/seatgeek/thefuzz) and setting these thresholds may produce different results.\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "Range: 0 to 100\n",
    "Higher values (e.g., 90‚Äì100) = stricter matching\n",
    "Lower values (e.g., 60‚Äì80) = more flexible, but may include incorrect matches\n",
    "If no threshold is provided, a default of 80 will be used.\n",
    "```\n",
    "\n",
    "If you're unsure, try starting with a value like 85, then adjust based on match quality.\n",
    "\n",
    "Setting the entity_instance_col Will change the column to match against, however this can be left as default for we are using the name from the DTB Data Model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18420377-0d0e-470e-841a-b3a75d4e4fdb",
   "metadata": {
    "collapsed": false,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Optional: Set a custom fuzzy match threshold (0‚Äì100)\n",
    "# fuzzy_threshold = 50  # <-- Change this if needed\n",
    "\n",
    "# Specify the column in your asset table that identifies your entity\n",
    "entity_instance_col = \"EntityInstanceDisplayId\" # <-- Change this if needed\n",
    "\n",
    "# Do not modify \n",
    "try:\n",
    "    fuzzy_threshold\n",
    "except NameError:\n",
    "    fuzzy_threshold = 50  # Default threshold\n",
    "result_df = OpenUSDToolkit.fuzzy_match_usd_assets(spark, df_usd_metadata, df_entity_instances, entity_instance_col, fuzzy_threshold)\n",
    "display(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7185cbcf-7ec1-43ee-8a3a-dc1732fc136d",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### üßá Step 4: Extract Matches to Table\n",
    "- This will save the data matched above into a table we can use within DTB.\n",
    "- You can optionally provide a `table_name` to store this output data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42df65c-b553-4ce4-a665-d428369d6783",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "table_name = \"MatchedUSDMetadata\"\n",
    "result_df.write.mode(\"overwrite\").format(\"delta\").saveAsTable(table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb6d01d-7a8d-4dd0-8c78-90a0172cbe7d",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### üõ†Ô∏è Step 5: Enrich Your USD File\n",
    "- You can optionally provide a file name for the enriched USD file that will include additional properties based on the matched asset data.\n",
    "- If you provide a new file name, the enriched USD data will be saved there.\n",
    "- If you do not provide a new file name, \"\\_enriched_\" will be appended to the original file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0058e254-684d-44bb-a3f1-5244d25b7e72",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Optional: Provide a file name for the enriched USD file\n",
    "enriched_usd_file_name = None  # e.g., \"OneRobotEnriched.usd\" or leave as None\n",
    "\n",
    "# Do not modify\n",
    "if enriched_usd_file_name:\n",
    "    enriched_usd_file_path = f\"/lakehouse/default/Files/{enriched_usd_file_name}\"\n",
    "else:\n",
    "    import os\n",
    "    base, ext = os.path.splitext(usd_file_name)\n",
    "    enriched_usd_file_path = f\"/lakehouse/default/Files/{base}_enriched{ext}\"\n",
    "\n",
    "OpenUSDToolkit.enrich_usd_with_dtb_assets(usd_file_path, enriched_usd_file_path, df_usd_metadata, result_df)\n",
    "print(f\"‚úÖ USD file enriched successfully! File saved to: {enriched_usd_file_path}\")\n",
    "OpenUSDToolkit.print_usd_file_details(f\"/lakehouse/default/Files/{base}_enriched{ext}\", onlyDTBID=True)"
   ]
  }
 ],
 "metadata": {
  "a365ComputeOptions": null,
  "dependencies": {
   "lakehouse": {}
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "synapse_pyspark",
   "language": null,
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "sessionKeepAliveTimeout": 0,
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  },
  "synapse_widget": {
   "state": {},
   "version": "0.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
