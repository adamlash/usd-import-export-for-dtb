{"cells":[{"cell_type":"markdown","source":["### üåê Step 0: Install required imports"],"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"99aca595-8b2c-4dd9-8809-7f4dc7403daf"},{"cell_type":"code","source":["# Pip installations\n","%pip install usd-core --quiet\n","%pip install spark --quiet\n","%pip install thefuzz --quiet\n","# Import Open USD MSFabric Package\n","%pip install /lakehouse/default/Files/openusd_msfabric_toolkit-0.1.0-py3-none-any.whl --quiet\n","# Imports\n","from pxr import Usd, UsdGeom, Sdf\n","from pyspark.sql import SparkSession\n","import pyspark.sql.functions as F\n","from openusd_msfabric_toolkit import OpenUSDToolkit\n","# Create Spark Session\n","spark = SparkSession.builder.getOrCreate()"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"68796ffc-fa13-4948-849e-e95fec179e3f"},{"cell_type":"markdown","source":["### üìù Step 1: Provide name of USD file, Asset data table, and Lakehouse\n","Please update the Python cell below.\n","Please note that your files must be located in the `/lakehouse/default/Files/` directory.\n","\n","Note, please just supply the file name - not the file path. Example file name:\n","```\n","PCR_8FT2_ALL_Complete_wOneRobot.usd\n","```"],"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"20fdee4d-97ee-44c0-9c94-88c213b421e3"},{"cell_type":"code","source":["# USD File Details\n","usd_file_name = \"iss.usdc\"  # Name of the USD file you want to enrich\n","usd_lakehouse_name = \"yourlakehouse\" # Name of the lakehouse in which your USD file is stored\n","\n","# Asset Data Details\n","entity_name = \"Module\" # Name of the Entity Type you wish to match with the USD Metadata. This is case sensitive!\n","dtb_item = \"yourdtb\" # Name of your DTB Instance. This is case sensitive!\n","\n","# Do not modify\n","usd_file_path = f\"/lakehouse/default/Files/{usd_file_name}\""],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0bbc2a18-7dd1-4458-9b33-2efcae4c08c7"},{"cell_type":"markdown","source":["### üìÇ Step 2: Extract metadata from your USD file\n","This step extracts metadata from prims of type Xform. This data will be stored in a table titled **ExtractedUSDMetadata** in your **default** Lakehouse."],"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"31b8679b-6f94-460f-9283-2f0bf1c62dea"},{"cell_type":"code","source":["# Do not modify\n","sql_query = f\"SELECT * FROM {usd_lakehouse_name}.extractedusdmetadata\"\n","df_usd_metadata = spark.sql(sql_query)\n","display(df_usd_metadata)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"4ff8f312-0865-4d1f-8e97-10135c6bb572"},{"cell_type":"markdown","source":["### üß© Step 3: Relate Asset Data and extracted USD metadata\n","This step fuzzy matches your asset data in your Lakehouse with the extracted USD metadata."],"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"e36a11fb-fd5f-412e-8ba3-9f705cef7100"},{"cell_type":"code","source":["# Do not modify\n","df_entity_instances = OpenUSDToolkit.read_entity_instances(spark, dtb_item, entity_name)\n","display(df_entity_instances)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"bf404013-fb9f-4e02-9eca-138fd2326d8e"},{"cell_type":"markdown","source":["The fuzzy matching threshold determines how closely the asset names must match the USD metadata in order to be considered a valid match. You may wish to set the thresholds of matching strength with the variable `fuzzy_threshold` . We are using the Fuzzy matching library called [TheFuzz](https://github.com/seatgeek/thefuzz) and setting these thresholds may produce different results.\n","\n","\n","\n","```\n","Range: 0 to 100\n","Higher values (e.g., 90‚Äì100) = stricter matching\n","Lower values (e.g., 60‚Äì80) = more flexible, but may include incorrect matches\n","If no threshold is provided, a default of 80 will be used.\n","```\n","\n","If you're unsure, try starting with a value like 85, then adjust based on match quality.\n","\n","Setting the entity_instance_col Will change the column to match against, however this can be left as default for we are using the name from the DTB Data Model.\n","\n"],"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"f1dbc72f-baa4-44ed-9e44-f75e1e3fc616"},{"cell_type":"code","source":["# Optional: Set a custom fuzzy match threshold (0‚Äì100)\n","# fuzzy_threshold = 50  # <-- Change this if needed\n","\n","# Specify the column in your asset table that identifies your entity\n","entity_instance_col = \"EntityInstanceDisplayId\" # <-- Change this if needed\n","\n","# Do not modify \n","try:\n","    fuzzy_threshold\n","except NameError:\n","    fuzzy_threshold = 50  # Default threshold\n","result_df = OpenUSDToolkit.fuzzy_match_usd_assets(spark, df_usd_metadata, df_entity_instances, entity_instance_col, fuzzy_threshold)\n","display(result_df)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"18420377-0d0e-470e-841a-b3a75d4e4fdb"},{"cell_type":"markdown","source":["### üßá Step 4: Extract Matches to Table\n","- This will save the data matched above into a table we can use within DTB.\n","- You can optionally provide a `table_name` to store this output data."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"7185cbcf-7ec1-43ee-8a3a-dc1732fc136d"},{"cell_type":"code","source":["table_name = \"MatchedUSDMetadata\"\n","result_df.write.mode(\"overwrite\").format(\"delta\").saveAsTable(table_name)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d42df65c-b553-4ce4-a665-d428369d6783"},{"cell_type":"markdown","source":["### üõ†Ô∏è Step 5: Enrich Your USD File\n","- You can optionally provide a file name for the enriched USD file that will include additional properties based on the matched asset data.\n","- If you provide a new file name, the enriched USD data will be saved there.\n","- If you do not provide a new file name, \"\\_enriched_\" will be appended to the original file path."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"ddb6d01d-7a8d-4dd0-8c78-90a0172cbe7d"},{"cell_type":"code","source":["# Optional: Provide a file name for the enriched USD file\n","enriched_usd_file_name = None  # e.g., \"OneRobotEnriched.usd\" or leave as None\n","\n","# Do not modify\n","if enriched_usd_file_name:\n","    enriched_usd_file_path = f\"/lakehouse/default/Files/{enriched_usd_file_name}\"\n","else:\n","    import os\n","    base, ext = os.path.splitext(usd_file_name)\n","    enriched_usd_file_path = f\"/lakehouse/default/Files/{base}_enriched{ext}\"\n","\n","OpenUSDToolkit.enrich_usd_with_dtb_assets(usd_file_path, enriched_usd_file_path, df_usd_metadata, result_df)\n","print(f\"‚úÖ USD file enriched successfully! File saved to: {enriched_usd_file_path}\")\n","OpenUSDToolkit.print_usd_file_details(f\"/lakehouse/default/Files/{base}_enriched{ext}\", onlyDTBID=True)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0058e254-684d-44bb-a3f1-5244d25b7e72"}],"metadata":{"language_info":{"name":"python"},"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"display_name":"synapse_pyspark","language":null,"name":"synapse_pyspark"},"a365ComputeOptions":null,"sessionKeepAliveTimeout":0,"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{}}},"nbformat":4,"nbformat_minor":5}